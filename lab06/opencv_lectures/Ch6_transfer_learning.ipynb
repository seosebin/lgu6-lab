{"cells":[{"cell_type":"markdown","metadata":{"id":"fCCtgpwC6yat"},"source":["# Tensorflow 재설치"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10552,"status":"ok","timestamp":1726220660353,"user":{"displayName":"Ji-hoon Jung","userId":"03169308685755834042"},"user_tz":-540},"id":"I_VSzTDm6oci","outputId":"99492db9-6b7a-444b-97c7-5d69e461dd5b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow==2.17.0 in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: absl-py\u003e=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.4.0)\n","Requirement already satisfied: astunparse\u003e=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.6.3)\n","Requirement already satisfied: flatbuffers\u003e=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,\u003e=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.6.0)\n","Requirement already satisfied: google-pasta\u003e=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.2.0)\n","Requirement already satisfied: h5py\u003e=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.11.0)\n","Requirement already satisfied: libclang\u003e=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (18.1.1)\n","Requirement already satisfied: ml-dtypes\u003c0.5.0,\u003e=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.4.0)\n","Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c5.0.0dev,\u003e=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.20.3)\n","Requirement already satisfied: requests\u003c3,\u003e=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (71.0.4)\n","Requirement already satisfied: six\u003e=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.16.0)\n","Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.4.0)\n","Requirement already satisfied: typing-extensions\u003e=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (4.12.2)\n","Requirement already satisfied: wrapt\u003e=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.16.0)\n","Requirement already satisfied: grpcio\u003c2.0,\u003e=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.64.1)\n","Requirement already satisfied: tensorboard\u003c2.18,\u003e=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.17.0)\n","Requirement already satisfied: keras\u003e=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem\u003e=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.37.1)\n","Requirement already satisfied: numpy\u003c2.0.0,\u003e=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.26.4)\n","Requirement already satisfied: wheel\u003c1.0,\u003e=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse\u003e=1.6.0-\u003etensorflow==2.17.0) (0.44.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras\u003e=3.2.0-\u003etensorflow==2.17.0) (13.8.1)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras\u003e=3.2.0-\u003etensorflow==2.17.0) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras\u003e=3.2.0-\u003etensorflow==2.17.0) (0.12.1)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow==2.17.0) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow==2.17.0) (3.8)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow==2.17.0) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow==2.17.0) (2024.8.30)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.18,\u003e=2.17-\u003etensorflow==2.17.0) (3.7)\n","Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.18,\u003e=2.17-\u003etensorflow==2.17.0) (0.7.2)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.18,\u003e=2.17-\u003etensorflow==2.17.0) (3.0.4)\n","Requirement already satisfied: MarkupSafe\u003e=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug\u003e=1.0.1-\u003etensorboard\u003c2.18,\u003e=2.17-\u003etensorflow==2.17.0) (2.1.5)\n","Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich-\u003ekeras\u003e=3.2.0-\u003etensorflow==2.17.0) (3.0.0)\n","Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich-\u003ekeras\u003e=3.2.0-\u003etensorflow==2.17.0) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich-\u003ekeras\u003e=3.2.0-\u003etensorflow==2.17.0) (0.1.2)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n","    status = run_func(*args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n","    return func(self, options, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 473, in run\n","    env = get_environment(lib_locations)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/__init__.py\", line 86, in get_environment\n","    return select_backend().Environment.from_paths(paths)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 263, in from_paths\n","    return cls(pkg_resources.WorkingSet(paths))\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 584, in __init__\n","    self.add_entry(entry)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 640, in add_entry\n","    for dist in find_distributions(entry, True):\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2101, in find_on_path\n","    factory = dist_factory(path_item, entry, only)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2109, in dist_factory\n","    is_dist_info = lower.endswith('.dist-info') and os.path.isdir(\n","  File \"/usr/lib/python3.10/genericpath.py\", line 42, in isdir\n","    st = os.stat(s)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1732, in isEnabledFor\n","    return self._cache[level]\n","KeyError: 50\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 8, in \u003cmodule\u003e\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n","    return command.main(cmd_args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n","    return self._main(args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n","    return run(options, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n","    logger.critical(\"Operation cancelled by user\")\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1523, in critical\n","    if self.isEnabledFor(CRITICAL):\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1740, in isEnabledFor\n","    level \u003e= self.getEffectiveLevel()\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1710, in getEffectiveLevel\n","    def getEffectiveLevel(self):\n","KeyboardInterrupt\n","^C\n"]}],"source":["# !pip install tensorflow==2.17.0"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":11927,"status":"ok","timestamp":1726220677885,"user":{"displayName":"Ji-hoon Jung","userId":"03169308685755834042"},"user_tz":-540},"id":"nRcmw92j65RT","outputId":"4ce98077-3ac8-4547-fd9c-9f54a271211c"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.17.0'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import tensorflow as tf\n","tf.__version__"]},{"cell_type":"markdown","metadata":{"id":"wXLBwMDsSEp3"},"source":["# 데이터 수집"]},{"cell_type":"markdown","metadata":{"id":"myKJJ6itSXj3"},"source":["## 데이터 내려받기\n","- 캐글에서 dogs-vs-cats 데이터셋을 다운로드하려면 캐글에 가입해야 한 후 생성한 API 키를 사용해야 합니다. 다운로드에 문제가 있다면 다음 명령으로 구글 드라이브에서 직접 다운로드할 수 있습니다."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":96},"executionInfo":{"elapsed":8616,"status":"ok","timestamp":1726220690281,"user":{"displayName":"Ji-hoon Jung","userId":"03169308685755834042"},"user_tz":-540},"id":"C4tI14SKSbxE","outputId":"70e4604f-d0e5-4557-c842-972b7ed274f4"},"outputs":[{"data":{"text/html":["\n","     \u003cinput type=\"file\" id=\"files-15b1716b-b2d2-4f5e-90b7-34dc72b62fb0\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" /\u003e\n","     \u003coutput id=\"result-15b1716b-b2d2-4f5e-90b7-34dc72b62fb0\"\u003e\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      \u003c/output\u003e\n","      \u003cscript\u003e// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) =\u003e {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable\u003c!Object\u003e} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) =\u003e {\n","    inputElement.addEventListener('change', (e) =\u003e {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) =\u003e {\n","    cancel.onclick = () =\u003e {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) =\u003e {\n","      const reader = new FileReader();\n","      reader.onload = (e) =\u003e {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position \u003c fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","\u003c/script\u003e "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving kaggle.json to kaggle.json\n"]},{"data":{"text/plain":["{'kaggle.json': b'{\"username\":\"j2hoon85\",\"key\":\"4158dd1c4656faad3eb215c381d916d1\"}'}"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["from google.colab import files\n","files.upload()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":413,"status":"ok","timestamp":1726220695237,"user":{"displayName":"Ji-hoon Jung","userId":"03169308685755834042"},"user_tz":-540},"id":"Lt9b__ZyTKqS"},"outputs":[],"source":["!mkdir ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10536,"status":"ok","timestamp":1726220706324,"user":{"displayName":"Ji-hoon Jung","userId":"03169308685755834042"},"user_tz":-540},"id":"Qw0Fak557NPN","outputId":"9b71d0b5-7425-4919-c6a0-ff1975585f4e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading dogs-vs-cats.zip to /content\n"," 99% 803M/812M [00:09\u003c00:00, 160MB/s]\n","100% 812M/812M [00:09\u003c00:00, 90.2MB/s]\n"]}],"source":["!kaggle competitions download -c dogs-vs-cats"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZrCugaSgTPFS"},"outputs":[],"source":["!unzip -qq dogs-vs-cats.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xKN29l7Z7OD9"},"outputs":[],"source":["!unzip -qq train.zip"]},{"cell_type":"markdown","metadata":{"id":"o1Gi8Lm0SQ5i"},"source":["## 이미지를 훈련, 검증, 테스트 디렉터리로 복사하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MQo965LeSUBl"},"outputs":[],"source":["import os, shutil, pathlib\n","\n","original_dir = pathlib.Path(\"train\")\n","new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n","\n","def make_subset(subset_name, start_index, end_index):\n","    for category in (\"cat\", \"dog\"):\n","        dir = new_base_dir / subset_name / category\n","        os.makedirs(dir)\n","        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n","        for fname in fnames:\n","            shutil.copyfile(src=original_dir / fname,\n","                            dst=dir / fname)\n","\n","make_subset(\"train\", start_index=0, end_index=1000)\n","make_subset(\"validation\", start_index=1000, end_index=1500)\n","make_subset(\"test\", start_index=1500, end_index=2500)"]},{"cell_type":"markdown","metadata":{"id":"9SwsY8g9SJ26"},"source":["## Image_dataset_from_directory를 사용하여 이미지 읽기"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"UJ4qXr8kSHsT"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2000 files belonging to 2 classes.\n","Found 1000 files belonging to 2 classes.\n","Found 2000 files belonging to 2 classes.\n"]}],"source":["from tensorflow.keras.utils import image_dataset_from_directory\n","\n","train_dataset = image_dataset_from_directory(\n","    new_base_dir / \"train\",\n","    image_size=(180, 180),\n","    batch_size=32)\n","validation_dataset = image_dataset_from_directory(\n","    new_base_dir / \"validation\",\n","    image_size=(180, 180),\n","    batch_size=32)\n","test_dataset = image_dataset_from_directory(\n","    new_base_dir / \"test\",\n","    image_size=(180, 180),\n","    batch_size=32)"]},{"cell_type":"markdown","metadata":{"id":"baENZDVMQdJj"},"source":["# 전이학습 예제"]},{"cell_type":"markdown","metadata":{"id":"rJ6C41_rSCz2"},"source":[]},{"cell_type":"markdown","metadata":{"id":"RThq0tQSRonz"},"source":["## 사전 훈련된 모델을 사용한 특성 추출"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sU7lyEBLQUWT"},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"markdown","metadata":{"id":"ENFyCq5uR3U8"},"source":["### VGG16 합성곱 기반 층 만들기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zvLQBM8CR6JP"},"outputs":[],"source":["conv_base = keras.applications.vgg16.VGG16(\n","    weights=\"imagenet\",\n","    include_top=False,\n","    input_shape=(180, 180, 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BNsXMcKmR7zH"},"outputs":[],"source":["conv_base.summary()"]},{"cell_type":"markdown","metadata":{"id":"4-N6iwphTikd"},"source":["### VGG16 특성과 해당 레이블 추출하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ZvkMh-oTjO3"},"outputs":[],"source":["import numpy as np\n","\n","def get_features_and_labels(dataset):\n","    all_features = []\n","    all_labels = []\n","    for images, labels in dataset:\n","        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n","        features = conv_base.predict(preprocessed_images)\n","        all_features.append(features)\n","        all_labels.append(labels)\n","    return np.concatenate(all_features), np.concatenate(all_labels)\n","\n","train_features, train_labels =  get_features_and_labels(train_dataset)\n","val_features, val_labels =  get_features_and_labels(validation_dataset)\n","test_features, test_labels =  get_features_and_labels(test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QPfFNpHeToVR"},"outputs":[],"source":["train_features.shape"]},{"cell_type":"markdown","metadata":{"id":"lBm4wje7TnQt"},"source":["### 밀집 연결 분류기 정의하고 훈련하기\n","- model save : https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dX8675iuTvJ6"},"outputs":[],"source":["inputs = keras.Input(shape=(5, 5, 512))\n","x = layers.Flatten()(inputs)\n","x = layers.Dense(256)(x)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(loss=\"binary_crossentropy\",\n","              optimizer=\"rmsprop\",\n","              metrics=[\"accuracy\"])\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","      filepath=\"feature_extraction.keras\",\n","      save_best_only=True,\n","      monitor=\"val_loss\")\n","]\n","\n","history = model.fit(\n","    train_features, train_labels,\n","    epochs=20,\n","    validation_data=(val_features, val_labels),\n","    callbacks=callbacks)"]},{"cell_type":"markdown","metadata":{"id":"DhTJEoI_UqPH"},"source":["### 결과 그래프 만들기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"trdnEDi8UuWF"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","acc = history.history[\"accuracy\"]\n","val_acc = history.history[\"val_accuracy\"]\n","loss = history.history[\"loss\"]\n","val_loss = history.history[\"val_loss\"]\n","epochs = range(1, len(acc) + 1)\n","plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n","plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n","plt.title(\"Training and validation accuracy\")\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n","plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n","plt.title(\"Training and validation loss\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ZoaeQBxUwNZ"},"outputs":[],"source":["test_model = keras.models.load_model(\n","    \"feature_extraction.keras\")\n","test_loss, test_acc = test_model.evaluate(test_features,test_labels)\n","print(f\"테스트 정확도: {test_acc:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"5W5ehUZpkJdV"},"source":["## 데이터 증식을 사용한 특성 추출\n"]},{"cell_type":"markdown","metadata":{"id":"X_m6-pi3kMYR"},"source":["### VGG16 합성곱 기반 층을 만들고 동결하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-h7IwN0dkM92"},"outputs":[],"source":["conv_base  = keras.applications.vgg16.VGG16(\n","    weights=\"imagenet\",\n","    include_top=False)\n","conv_base.trainable = False"]},{"cell_type":"markdown","metadata":{"id":"oED13bJjkQCB"},"source":["### 동결하기 전과 후에 훈련 가능한 가중치 리스트를 출력하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ia9JcNJkkRak"},"outputs":[],"source":["conv_base.trainable = True\n","print(\"합성곱 기반 층을 동결하기 전의 훈련 가능한 가중치 개수:\",\n","      len(conv_base.trainable_weights))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l41yHAU1kSvX"},"outputs":[],"source":["conv_base.trainable = False\n","print(\"합성곱 기반 층을 동결한 후의 훈련 가능한 가중치 개수:\",\n","      len(conv_base.trainable_weights))"]},{"cell_type":"markdown","metadata":{"id":"_sUwBNZikVW5"},"source":["### 데이터 증식 단계와 밀집 분류기를 합성곱 기반 층에 추가하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"12wwF9X2kWpD"},"outputs":[],"source":["data_augmentation = keras.Sequential(\n","    [\n","        layers.RandomFlip(\"horizontal\"),\n","        layers.RandomRotation(0.1),\n","        layers.RandomZoom(0.2),\n","    ]\n",")\n","\n","inputs = keras.Input(shape=(180, 180, 3))\n","x = data_augmentation(inputs)\n","x = keras.applications.vgg16.preprocess_input(x)\n","x = conv_base(x)\n","x = layers.Flatten()(x)\n","x = layers.Dense(256)(x)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(loss=\"binary_crossentropy\",\n","              optimizer=\"rmsprop\",\n","              metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"S9M5TpVokYRn"},"outputs":[],"source":["callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","        filepath=\"feature_extraction_with_data_augmentation.keras\",\n","        save_best_only=True,\n","        monitor=\"val_loss\")\n","]\n","history = model.fit(\n","    train_dataset,\n","    epochs=50,\n","    validation_data=validation_dataset,\n","    callbacks=callbacks)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B2yS-5Z3kcnz"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","acc = history.history[\"accuracy\"]\n","val_acc = history.history[\"val_accuracy\"]\n","loss = history.history[\"loss\"]\n","val_loss = history.history[\"val_loss\"]\n","epochs = range(1, len(acc) + 1)\n","plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n","plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n","plt.title(\"Training and validation accuracy\")\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n","plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n","plt.title(\"Training and validation loss\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"_8jyD-U3kfTP"},"source":["### 테스트 모델에서 평가하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ux2J8Aajkhr7"},"outputs":[],"source":["test_model = keras.models.load_model(\n","    \"feature_extraction_with_data_augmentation.keras\")\n","test_loss, test_acc = test_model.evaluate(test_dataset)\n","print(f\"테스트 정확도: {test_acc:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"-plfCKnvkjCt"},"source":["## 사전 훈련된 모델 미세 조정하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AZvd4OIAkk6T"},"outputs":[],"source":["conv_base.summary()"]},{"cell_type":"markdown","metadata":{"id":"TngXymvxkmbJ"},"source":["\n","### 마지막에서 네 번째 층까지 모든 층 동결하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RQTzWKQMknCb"},"outputs":[],"source":["conv_base.trainable = True\n","for layer in conv_base.layers[:-4]:\n","    layer.trainable = False"]},{"cell_type":"markdown","metadata":{"id":"7ajOIkeZkqcg"},"source":["### 모델 미세 조정하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"thu1eadgkrDy"},"outputs":[],"source":["model.compile(loss=\"binary_crossentropy\",\n","              optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n","              metrics=[\"accuracy\"])\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","        filepath=\"fine_tuning.keras\",\n","        save_best_only=True,\n","        monitor=\"val_loss\")\n","]\n","history = model.fit(\n","    train_dataset,\n","    epochs=30,\n","    validation_data=validation_dataset,\n","    callbacks=callbacks)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UHBDEEtpkueh"},"outputs":[],"source":["model = keras.models.load_model(\"fine_tuning.keras\")\n","test_loss, test_acc = model.evaluate(test_dataset)\n","print(f\"테스트 정확도: {test_acc:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"HhuDde20kt7N"},"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNq2hscS2+YVTo2lei8BOyO","name":"","toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}